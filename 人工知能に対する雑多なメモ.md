フィルター処理をかけ,特徴をきわだたせ,圧縮を繰り返す
#教師あり学習の弱点
人間が教師データを作った範囲内の知識しか学習できない点  
人間が知らない「未知の知識」をデータから引き出すことはできない

# 機械学習とは何か
機械自身が例を通じて学習する手法.
<!-- たくさんのデータから,人にとって有益なルールや法則を見つけることを指す.  -->
厳密な定義はなく,人工知能や統計,データマイニングなどの手法を総称して機械学習と呼んでいる.


# オンライン機械学習
データ分布変化に強い技術

# 機械学習の良いところ  
分析するデータの量が増えるに従い,ルールの精度が高くなること  
コンピュータの性能や容量が向上するにつれて,人間が見つけたルールよりも,機械が見つけ出したルールの方が精度が高くなるケースが増えている.  

# 機械学習は万能ではない
学習していない事象には対応できない.  
しかも,通常は起きないイレギュラーな事例を学習させすぎる(過学習)と,通常時の認識精度は下がる.  
苦手とするタスクがある.  
> 国立情報学研究所(NII)社会共有知研究センター長 新井紀子教授「表現が異なる2つの文章の意味が同じかどうか判断する『断言関係認識』なども機械学習は苦手とする」  
データがないと学習できない.データそのものが間違っている恐れもある.

# 機械学習の課題  
一般的な機械学習のソフトには,リアルタイム性やスケーラビリティ(拡張性)が欠けている.

***
> 新薬の候補物質の探索に機械学習を応用している京都大学大学院 医学研究科 奥野恭史特定教授「deep learningは大量の教師ありデータが利用できる例では威力を発揮する一方,データ量が少ない場合はsupport vector macineの方が優れた結果を出す」

***

deep learning (深層学習)の手法は人工知能研究の初期からあるニューラルネットの一つ  
deep learning (深層学習) = 表現学習

#パターン認識とは
観測される具体的事象を,それが属すべき抽象的な概念に対応分けする処理のこと

# 経路計画  
最適と思われる経路をリアルタイムに選択する必要がある.  
これは膨大なパターンの中から最適なものを見つけ出す一緒の探索処理であり,多大な処理能力を要する.処理が高速になれば探索できるパターンが増えるので より最適な経路を見つけやすい
***

# パーセプトロン
線形識別器の基礎(今は)
究極的には「識別関数」の値の大小で分類する.

$$y=\mathbf{w^{\mathrm{T}}x}$$

$y$: 返値（「±の符号」が大事！）  
$\mathbf{w^{\mathrm{T}}}$: 重みベクトル（学習結果）  
$\mathbf{x}$: 入力信号（これから識別したいもの）

ちなみに  
> パーセプトロンが分からなきゃ、 サポートベクターマシンも分からない！  
パーセプトロンが分かれば、 サポートベクターマシンなんて余裕！  
（おそらく）史上最強の 機械学習分類器  

とのことです.  
slideshare:
[Simple perceptron by TJO](http://www.slideshare.net/takashijozaki1/simple-perceptron-by-tjo) from [Takashi J Ozaki](http://www.slideshare.net/takashijozaki1)を参考にさせてもらいました.


#googleが使ったRNN(recurrent neural network:再帰的ニューラルネットワーク)
googleが使ったRNNはLSTM(long short term memory)と呼ばれるタイプのもの.  
LSTMは,過去に入力したデータに含まれる情報が,何度かネットワークを循環させた後でも高い精度で取り出せる特徴がある.  
いわば,ニューラルネットに揮発性メモリーのような役割を持たせることができる.
***
Googleの論文における英仏翻訳では隠れ層の出力(文章全体の意味)を8000次元のベクトルで表現している.
ここ数年,自然言語解析の世界では単語が持つ意味や概念を数百次元のベクトルで表現する試みが盛んに行われている.

#DeepMind
ゲームごとにソフトウェアを最適化してるのではなく,単一プログラムで異なるビデオゲームに対応できる

# Jeopardy!の際のIBM Watsonの中核アルゴリズム検索方式アーキテクチャ「DeepQA」の4つのプロセス
1. Question Analysis  
 何が問われているか,解析
1. Hypothesis Generation  
解答候補,仮説(Hypothesis)を生成
1. Hypothesis & Evidence Scoring  
機械学習に基づき,解答候補が正しいか検証,その確度を算定(プロセッサ上で並列処理)
1. Final Merging & Ranking  
過去のJeopardy!の質問の解析から,経験的に正解率を算定

複数の独立したアルゴリズムを並列に動作させ,解答候補を探索.参照するデータ200GB程度を,10TBのメモリ上で並列処理

# コンピュータ将棋を例に「評価関数」のモデルをシンプルに書く
$W^t =$ 重み , $x =$ 特徴(駒の種類,数,位置関係,王将の危険度等の要素),  
$f(x_{n}) = W^t_{1} * x_{1} + W^t_{2} * x_{2} +...+W^t_{n} * x_{n}$  
重みベクトルと特徴ベクトルの積として表現  
モデルを作る上で最も重要なのが重みの調整で,あらかじめ決めた重みがどの程度適合しているかを統計的手法による検証を繰り返す.  

# D-Wave
量子力学の焼きなまし現象が発生する実験装置  
D-Waveの中で現実の世界の自然現象と同じ現象が実際に発生していることが従来型コンピュータとの違い.
従来型コンピュータは,自然現象をシミュレーションすることはできるが実際の現象を発生させることはできない.
D-Waveが採用する量子アニーリング型は,幅広い種類のNP完全問題を,古典的コンピューターに比べて桁違いに早く解けるとされている.  
ある種のデータ検索問題では,古典的コンピュータなら演算時間が2のN乗で増大するところを,量子アニーリングなら2のN/2乗に抑えられる.
***
N ＝ 20なら,量子アニーリング型なら古典的コンピューターの約1,000倍高速に解くことができる計算.  
だが,量子アニーリング型でも,演算時間が指数関数的に増えることに変わらない.
N ＝ 10の演算を古典的コンピュータが解く時間で,量子アニーリングでは2倍のN ＝ 20が解ける,というくらい.一方,GoogleやFacebookが今まさに解きたいと考えているグラフ演算は,要素Nが10万,100万のオーダー.
このレベルでは,量子アニーリング型では実時間で計算を完了できそうもない.
レーザーネットワーク型の量子コンピュータでは,計算量をNに比例するレベルまで押さえ込める見込み.  
コンピュータ科学者は現在,グラフ演算の近似解を導くための,古典的コンピューター向け高速アルゴリズムを開発,利用している.量子コンピュータが目指すべきは,こうした近似アルゴリズムに圧倒的に勝つレベルの演算性能.

# 深層学習の略語表記
NN : Neural Network  
DNN : Deep Neural Network  
CNN : Convolutional Neural Network  
RNN : Recurrent Neural Network  
LSTM : Long Short-Term Memory

#### 参考文献
1) 日経コンピュータ (編さん):『[Ｔｈｅ　Ｎｅｘｔ　Ｔｅｃｈｎｏｌｏｇｙ　脳に迫る人工知能　最前線](http://amzn.to/1hOLVCC)』日経BP社, 2015.
2) 海野 裕也  (著), 岡野原 大輔  (著), 得居 誠也  (著), 徳永 拓之  (著):『[オンライン機械学習 (機械学習プロフェッショナルシリーズ)](http://amzn.to/1Uw0EE3)』講談社, 2015.
